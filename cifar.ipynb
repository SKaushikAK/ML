{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b234c1b3-fc3d-4b70-9da5-4724c314d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d277fffa-e943-4ddb-9ca6-80fbe7476c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        batch = pickle.load(f, encoding='bytes')\n",
    "        data = batch[b'data']\n",
    "        labels = np.array(batch[b'labels'])\n",
    "        return data, labels\n",
    "\n",
    "def load_cifar10_data():\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(1, 6):\n",
    "        data, labels = load_cifar10_batch(f'datasets/cifar-10-batches-py/data_batch_{i}')\n",
    "        x_train.append(data)\n",
    "        y_train.append(labels)\n",
    "\n",
    "    x_train = np.concatenate(x_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "\n",
    "    x_test, y_test = load_cifar10_batch(f'datasets/cifar-10-batches-py/test_batch')\n",
    "\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5d2112-a7f6-4938-94c9-1cc9ba1ec10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load_cifar10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b179244-6cf1-4903-9786-02f4e7afa3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26195f1-df7e-479c-b755-e1fdf5da009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3072  # 32x32x3 pixels\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "output_size = 10  # CIFAR-10 has 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc03276-1607-43b9-8df5-5ae9c3a924cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"W1\": np.random.randn(input_size, hidden_size1) * np.sqrt(2.0 / input_size),\n",
    "    \"b1\": np.zeros((1, hidden_size1)),\n",
    "    \"W2\": np.random.randn(hidden_size1, hidden_size2) * np.sqrt(2.0 / hidden_size1),\n",
    "    \"b2\": np.zeros((1, hidden_size2)),\n",
    "    \"W3\": np.random.randn(hidden_size2, output_size) * np.sqrt(2.0 / hidden_size2),\n",
    "    \"b3\": np.zeros((1, output_size))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f4d4e91-a773-4259-a647-f490d01fb4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "    return expZ / np.sum(expZ, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c107dc-c8a6-492d-81db-e0938309e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, weights):\n",
    "    Z1 = np.dot(X, weights[\"W1\"]) + weights[\"b1\"]\n",
    "    A1 = relu(Z1)\n",
    "\n",
    "    Z2 = np.dot(A1, weights[\"W2\"]) + weights[\"b2\"]\n",
    "    A2 = relu(Z2)\n",
    "\n",
    "    Z3 = np.dot(A2, weights[\"W3\"]) + weights[\"b3\"]\n",
    "    A3 = softmax(Z3)\n",
    "\n",
    "    return Z1, A1, Z2, A2, Z3, A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfa678a1-120f-42b1-b5de-a689335a9954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(Y_pred, Y_true, weights, lambda_=0.01):\n",
    "    m = Y_true.shape[0]\n",
    "    log_likelihood = -np.log(Y_pred[range(m), Y_true])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "\n",
    "    # L2 Regularization\n",
    "    L2_regularization = (lambda_ / (2 * m)) * (\n",
    "        np.sum(weights[\"W1\"] ** 2) + np.sum(weights[\"W2\"] ** 2) + np.sum(weights[\"W3\"] ** 2)\n",
    "    )\n",
    "    return loss + L2_regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f8aa75-814a-4188-938a-c420b45dad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(X, Y_true, A1, A2, A3, weights, learning_rate, lambda_):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # One-hot encoding of labels\n",
    "    Y_one_hot = np.zeros((m, output_size))\n",
    "    Y_one_hot[np.arange(m), Y_true] = 1\n",
    "\n",
    "    # Compute gradients\n",
    "    dZ3 = A3 - Y_one_hot\n",
    "    dW3 = (np.dot(A2.T, dZ3) + lambda_ * weights[\"W3\"]) / m\n",
    "    db3 = np.sum(dZ3, axis=0, keepdims=True) / m\n",
    "\n",
    "    dA2 = np.dot(dZ3, weights[\"W3\"].T)\n",
    "    dZ2 = dA2 * (A2 > 0)  # ReLU derivative\n",
    "    dW2 = (np.dot(A1.T, dZ2) + lambda_ * weights[\"W2\"]) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "    dA1 = np.dot(dZ2, weights[\"W2\"].T)\n",
    "    dZ1 = dA1 * (A1 > 0)  # ReLU derivative\n",
    "    dW1 = (np.dot(X.T, dZ1) + lambda_ * weights[\"W1\"]) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "    # Update weights\n",
    "    weights[\"W1\"] -= learning_rate * dW1\n",
    "    weights[\"b1\"] -= learning_rate * db1\n",
    "    weights[\"W2\"] -= learning_rate * dW2\n",
    "    weights[\"b2\"] -= learning_rate * db2\n",
    "    weights[\"W3\"] -= learning_rate * dW3\n",
    "    weights[\"b3\"] -= learning_rate * db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e69d58-bff0-4a85-9f7f-b2927cc71200",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 64\n",
    "lambda_ = 0.01 # L2 regularization factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41eff1b4-91c9-436d-af61-0d42188af288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.3072\n",
      "Epoch 2/50, Loss: 2.3041\n",
      "Epoch 3/50, Loss: 2.3025\n",
      "Epoch 4/50, Loss: 2.3026\n",
      "Epoch 5/50, Loss: 2.3027\n",
      "Epoch 6/50, Loss: 2.3026\n",
      "Epoch 7/50, Loss: 2.3025\n",
      "Epoch 8/50, Loss: 2.3025\n",
      "Epoch 9/50, Loss: 2.3026\n",
      "Epoch 10/50, Loss: 2.3025\n",
      "Epoch 11/50, Loss: 2.3025\n",
      "Epoch 12/50, Loss: 2.3026\n",
      "Epoch 13/50, Loss: 2.3026\n",
      "Epoch 14/50, Loss: 2.3025\n",
      "Epoch 15/50, Loss: 2.3026\n",
      "Epoch 16/50, Loss: 2.3025\n",
      "Epoch 17/50, Loss: 2.3026\n",
      "Epoch 18/50, Loss: 2.3026\n",
      "Epoch 19/50, Loss: 2.3025\n",
      "Epoch 20/50, Loss: 2.3026\n",
      "Epoch 21/50, Loss: 2.3026\n",
      "Epoch 22/50, Loss: 2.3026\n",
      "Epoch 23/50, Loss: 2.3026\n",
      "Epoch 24/50, Loss: 2.3026\n",
      "Epoch 25/50, Loss: 2.3026\n",
      "Epoch 26/50, Loss: 2.3026\n",
      "Epoch 27/50, Loss: 2.3026\n",
      "Epoch 28/50, Loss: 2.3026\n",
      "Epoch 29/50, Loss: 2.3026\n",
      "Epoch 30/50, Loss: 2.3026\n",
      "Epoch 31/50, Loss: 2.3026\n",
      "Epoch 32/50, Loss: 2.3026\n",
      "Epoch 33/50, Loss: 2.3026\n",
      "Epoch 34/50, Loss: 2.3026\n",
      "Epoch 35/50, Loss: 2.3026\n",
      "Epoch 36/50, Loss: 2.3026\n",
      "Epoch 37/50, Loss: 2.3026\n",
      "Epoch 38/50, Loss: 2.3026\n",
      "Epoch 39/50, Loss: 2.3026\n",
      "Epoch 40/50, Loss: 2.3026\n",
      "Epoch 41/50, Loss: 2.3026\n",
      "Epoch 42/50, Loss: 2.3026\n",
      "Epoch 43/50, Loss: 2.3026\n",
      "Epoch 44/50, Loss: 2.3026\n",
      "Epoch 45/50, Loss: 2.3026\n",
      "Epoch 46/50, Loss: 2.3026\n",
      "Epoch 47/50, Loss: 2.3026\n",
      "Epoch 48/50, Loss: 2.3026\n",
      "Epoch 49/50, Loss: 2.3026\n",
      "Epoch 50/50, Loss: 2.3026\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    shuffle_indices = np.random.permutation(x_train.shape[0])\n",
    "    X_train, y_train = x_train[shuffle_indices], y_train[shuffle_indices]\n",
    "\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        X_batch = x_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "        Z1, A1, Z2, A2, Z3, A3 = forward_propagation(X_batch, weights)\n",
    "\n",
    "        learning_rate = 0.01 / (1 + 0.01 * epoch) # Learning rate decay\n",
    "        backpropagation(X_batch, y_batch, A1, A2, A3, weights, learning_rate, lambda_)\n",
    "\n",
    "\n",
    "    _, _, _, _, _, train_pred = forward_propagation(x_train, weights)\n",
    "    train_loss = compute_loss(train_pred, y_train, weights, lambda_)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa5e98b1-1a25-4518-a18f-13c597dfccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "def predict(X, weights):\n",
    "    _, _, _, _, _, A3 = forward_propagation(X, weights)\n",
    "    return np.argmax(A3, axis=1)\n",
    "\n",
    "y_pred = predict(x_test, weights)\n",
    "accuracy = np.mean(y_pred == y_test) * 100\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f60085ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.2756 - loss: 1.9934 - val_accuracy: 0.3098 - val_loss: 1.8702\n",
      "Epoch 2/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.3756 - loss: 1.7550 - val_accuracy: 0.3846 - val_loss: 1.7112\n",
      "Epoch 3/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4091 - loss: 1.6555 - val_accuracy: 0.4148 - val_loss: 1.6583\n",
      "Epoch 4/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.4273 - loss: 1.6060 - val_accuracy: 0.4304 - val_loss: 1.5980\n",
      "Epoch 5/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4397 - loss: 1.5774 - val_accuracy: 0.4370 - val_loss: 1.5572\n",
      "Epoch 6/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4507 - loss: 1.5334 - val_accuracy: 0.4494 - val_loss: 1.5412\n",
      "Epoch 7/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4579 - loss: 1.5149 - val_accuracy: 0.4638 - val_loss: 1.5118\n",
      "Epoch 8/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4707 - loss: 1.4788 - val_accuracy: 0.4530 - val_loss: 1.5393\n",
      "Epoch 9/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4763 - loss: 1.4712 - val_accuracy: 0.4604 - val_loss: 1.5014\n",
      "Epoch 10/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4824 - loss: 1.4505 - val_accuracy: 0.4520 - val_loss: 1.5317\n",
      "Epoch 11/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4856 - loss: 1.4339 - val_accuracy: 0.4572 - val_loss: 1.5239\n",
      "Epoch 12/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4886 - loss: 1.4275 - val_accuracy: 0.4538 - val_loss: 1.5283\n",
      "Epoch 13/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4962 - loss: 1.4087 - val_accuracy: 0.4744 - val_loss: 1.4822\n",
      "Epoch 14/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4959 - loss: 1.4122 - val_accuracy: 0.4720 - val_loss: 1.4928\n",
      "Epoch 15/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5039 - loss: 1.3975 - val_accuracy: 0.4786 - val_loss: 1.4805\n",
      "Epoch 16/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5070 - loss: 1.3827 - val_accuracy: 0.4814 - val_loss: 1.4814\n",
      "Epoch 17/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5054 - loss: 1.3892 - val_accuracy: 0.4718 - val_loss: 1.4796\n",
      "Epoch 18/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5126 - loss: 1.3702 - val_accuracy: 0.4964 - val_loss: 1.4338\n",
      "Epoch 19/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5118 - loss: 1.3576 - val_accuracy: 0.4568 - val_loss: 1.5257\n",
      "Epoch 20/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5209 - loss: 1.3479 - val_accuracy: 0.4826 - val_loss: 1.4542\n",
      "Epoch 21/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5180 - loss: 1.3468 - val_accuracy: 0.4796 - val_loss: 1.4637\n",
      "Epoch 22/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5198 - loss: 1.3406 - val_accuracy: 0.4818 - val_loss: 1.4367\n",
      "Epoch 23/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5210 - loss: 1.3322 - val_accuracy: 0.4848 - val_loss: 1.4707\n",
      "Epoch 24/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5265 - loss: 1.3334 - val_accuracy: 0.4868 - val_loss: 1.4487\n",
      "Epoch 25/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5213 - loss: 1.3320 - val_accuracy: 0.4900 - val_loss: 1.4278\n",
      "Epoch 26/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5287 - loss: 1.3224 - val_accuracy: 0.4950 - val_loss: 1.4364\n",
      "Epoch 27/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5305 - loss: 1.3155 - val_accuracy: 0.4854 - val_loss: 1.4632\n",
      "Epoch 28/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5353 - loss: 1.2966 - val_accuracy: 0.4890 - val_loss: 1.4406\n",
      "Epoch 29/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5385 - loss: 1.2951 - val_accuracy: 0.4822 - val_loss: 1.4920\n",
      "Epoch 30/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5333 - loss: 1.3108 - val_accuracy: 0.4872 - val_loss: 1.4343\n",
      "Epoch 31/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5401 - loss: 1.2918 - val_accuracy: 0.5104 - val_loss: 1.4059\n",
      "Epoch 32/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5408 - loss: 1.2814 - val_accuracy: 0.4800 - val_loss: 1.4853\n",
      "Epoch 33/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5424 - loss: 1.2867 - val_accuracy: 0.4974 - val_loss: 1.4174\n",
      "Epoch 34/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5450 - loss: 1.2775 - val_accuracy: 0.4874 - val_loss: 1.4558\n",
      "Epoch 35/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5421 - loss: 1.2795 - val_accuracy: 0.5086 - val_loss: 1.4064\n",
      "Epoch 36/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5498 - loss: 1.2598 - val_accuracy: 0.4942 - val_loss: 1.4375\n",
      "Epoch 37/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5482 - loss: 1.2665 - val_accuracy: 0.5038 - val_loss: 1.4217\n",
      "Epoch 38/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5520 - loss: 1.2513 - val_accuracy: 0.4912 - val_loss: 1.4821\n",
      "Epoch 39/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5478 - loss: 1.2610 - val_accuracy: 0.5016 - val_loss: 1.4171\n",
      "Epoch 40/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5503 - loss: 1.2538 - val_accuracy: 0.4932 - val_loss: 1.4266\n",
      "Epoch 41/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5482 - loss: 1.2650 - val_accuracy: 0.5080 - val_loss: 1.4058\n",
      "Epoch 42/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5588 - loss: 1.2452 - val_accuracy: 0.4956 - val_loss: 1.4535\n",
      "Epoch 43/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5590 - loss: 1.2461 - val_accuracy: 0.4836 - val_loss: 1.4636\n",
      "Epoch 44/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5584 - loss: 1.2389 - val_accuracy: 0.4996 - val_loss: 1.4339\n",
      "Epoch 45/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5589 - loss: 1.2394 - val_accuracy: 0.4874 - val_loss: 1.4434\n",
      "Epoch 46/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5617 - loss: 1.2340 - val_accuracy: 0.4944 - val_loss: 1.4527\n",
      "Epoch 47/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5578 - loss: 1.2358 - val_accuracy: 0.4958 - val_loss: 1.4414\n",
      "Epoch 48/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5606 - loss: 1.2329 - val_accuracy: 0.4986 - val_loss: 1.4306\n",
      "Epoch 49/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5608 - loss: 1.2263 - val_accuracy: 0.4812 - val_loss: 1.5202\n",
      "Epoch 50/50\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5638 - loss: 1.2208 - val_accuracy: 0.4942 - val_loss: 1.4474\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4911 - loss: 1.4543\n",
      "Test Accuracy: 48.99%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c3b923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59  43  50 ... 140  84  72]\n",
      " [154 126 105 ... 139 142 144]\n",
      " [255 253 253 ...  83  83  84]\n",
      " ...\n",
      " [ 35  40  42 ...  77  66  50]\n",
      " [189 186 185 ... 169 171 171]\n",
      " [229 236 234 ... 173 162 161]] [6 9 9 ... 9 1 1]\n",
      "Epoch 1/50\n",
      "\u001b[1m648/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2616 - loss: 2.0362"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 53\u001b[0m\n\u001b[0;32m     48\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     49\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     50\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m     55\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m ):\n\u001b[0;32m    219\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gen_optional_ops\u001b[38;5;241m.\u001b[39moptional_has_value(\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor, name\u001b[38;5;241m=\u001b[39mname\n\u001b[0;32m    178\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[1;34m(optional, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m    173\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptionalHasValue\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, optional)\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_cifar10_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        batch = pickle.load(f, encoding='bytes')\n",
    "        data = batch[b'data']\n",
    "        labels = np.array(batch[b'labels'])\n",
    "        return data, labels\n",
    "\n",
    "def load_cifar10_data(base_path):\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(1, 6):\n",
    "        data, labels = load_cifar10_batch(os.path.join(base_path, f'data_batch_{i}'))\n",
    "        x_train.append(data)\n",
    "        y_train.append(labels)\n",
    "\n",
    "    x_train = np.concatenate(x_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    print(x_train, y_train)\n",
    "\n",
    "    x_test, y_test = load_cifar10_batch(os.path.join(base_path, 'test_batch'))\n",
    "\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# Load from local path\n",
    "x_train, y_train, x_test, y_test = load_cifar10_data(r'datasets/cifar-10-batches-py')\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(3072,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=64, validation_split=0.1)\n",
    "# Evaluate\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test Accuracy: {acc * 100:.2f}%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f8d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
